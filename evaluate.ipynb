{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["pip -q install evaluate==0.3.0 jiwer==2.5.1"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# login wandb\n","import wandb\n","wandb.login(key = '')"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-05-30T07:35:24.028651Z","iopub.status.busy":"2024-05-30T07:35:24.028277Z","iopub.status.idle":"2024-05-30T07:35:33.040564Z","shell.execute_reply":"2024-05-30T07:35:33.039752Z","shell.execute_reply.started":"2024-05-30T07:35:24.028618Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["2024-05-30 07:35:28.583485: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-05-30 07:35:28.583557: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-05-30 07:35:28.585167: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"]}],"source":["import os\n","os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n","\n","import torch\n","from transformers import WhisperProcessor, WhisperForConditionalGeneration\n","from transformers import TrainingArguments, Trainer\n","\n","import datasets\n","from datasets import load_dataset, DatasetDict\n","from dataclasses import dataclass\n","\n","from typing import Dict, List, Optional, Union\n","import numpy as np\n","import evaluate\n","\n","wer_metric = evaluate.load(\"wer\")\n","bleu_metric = evaluate.load(\"bleu\")\n","cer_metric = evaluate.load(\"cer\")"]},{"cell_type":"markdown","metadata":{},"source":["# Build data"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-05-30T07:35:33.042783Z","iopub.status.busy":"2024-05-30T07:35:33.042199Z","iopub.status.idle":"2024-05-30T07:35:33.055560Z","shell.execute_reply":"2024-05-30T07:35:33.054380Z","shell.execute_reply.started":"2024-05-30T07:35:33.042751Z"},"trusted":true},"outputs":[],"source":["@dataclass\n","class DataCollatorWhisperCTCEncoder:\n","    processor: WhisperProcessor\n","    padding: Union[bool, str] = True\n","    max_length: Optional[int] = None\n","    truncation: Optional[bool] = True\n","    max_length_labels: Optional[int] = None\n","    pad_to_multiple_of: Optional[int] = None\n","    pad_to_multiple_of_labels: Optional[int] = None\n","    \n","    def __call__(self, features: List[Dict[str, np.ndarray]]) -> Dict[str, torch.Tensor]:\n","        batch_audio = []\n","        batch_label = []\n","\n","        batch_size = len(features)\n","\n","        for batch_idx in range(batch_size):\n","            batch_audio.append(features[batch_idx]['input_features'])\n","            batch_label.append(features[batch_idx]['label'])\n","\n","        data = list(zip(batch_audio, batch_label))\n","        # random.shuffle(data)\n","        \n","        batch_audio = [item[0] for item in data]\n","        batch_label = [item[1] for item in data]\n","\n","        batch = self.processor.feature_extractor(\n","            batch_audio,\n","            truncation=self.truncation,\n","            sampling_rate = 16000,\n","            pad_to_multiple_of=self.pad_to_multiple_of,\n","            return_tensors=\"pt\",\n","        )\n","        \n","        batch_label_id = [self.processor.tokenizer(item, truncation=True, max_length=448)['input_ids'] for item in batch_label]\n","        label_features = [{\"input_ids\": np.asarray(item)} for item in batch_label_id]\n","        labels_batch = self.processor.tokenizer.pad(label_features, return_tensors=\"pt\")\n","        labels = labels_batch[\"input_ids\"].masked_fill(labels_batch.attention_mask.ne(1), -100)\n","\n","        batch[\"labels\"] = labels\n","        return batch"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-05-30T07:35:33.057612Z","iopub.status.busy":"2024-05-30T07:35:33.057267Z","iopub.status.idle":"2024-05-30T07:35:35.976629Z","shell.execute_reply":"2024-05-30T07:35:35.975623Z","shell.execute_reply.started":"2024-05-30T07:35:33.057580Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c5a02cb7e666446faf0f08fffd295493","version_major":2,"version_minor":0},"text/plain":["Resolving data files:   0%|          | 0/33 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"}],"source":["youtube = DatasetDict()\n","youtube[\"test\"] = load_dataset('linhtran92/viet_youtube_asr_corpus_v2', split=\"test\")"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-05-30T07:35:35.978130Z","iopub.status.busy":"2024-05-30T07:35:35.977839Z","iopub.status.idle":"2024-05-30T07:35:36.037222Z","shell.execute_reply":"2024-05-30T07:35:36.036518Z","shell.execute_reply.started":"2024-05-30T07:35:35.978104Z"},"trusted":true},"outputs":[],"source":["def prepare_dataset(examples):\n","    examples['label'] = examples[\"transcription\"]\n","    examples[\"input_features\"] = examples[\"audio\"]['array']\n","    return examples\n","\n","all_dataset_test_vectorized = youtube[\"test\"].map(\n","    prepare_dataset,\n","    num_proc=8,\n","    remove_columns=youtube[\"test\"].column_names,\n",") "]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-05-30T07:35:36.039572Z","iopub.status.busy":"2024-05-30T07:35:36.039294Z","iopub.status.idle":"2024-05-30T07:35:36.119329Z","shell.execute_reply":"2024-05-30T07:35:36.118641Z","shell.execute_reply.started":"2024-05-30T07:35:36.039547Z"},"trusted":true},"outputs":[],"source":["# Using to split test set if OOM\n","# num_rows = len(all_dataset_test_vectorized)\n","# batch_size = 700\n","# num_splits = num_rows // batch_size + (1 if num_rows % batch_size != 0 else 0)\n","# splits = []\n","\n","# for i in range(num_splits):\n","#     start_idx = i * batch_size\n","#     end_idx = start_idx + batch_size\n","#     split = all_dataset_test_vectorized.select(range(start_idx, min(end_idx, num_rows)))\n","#     splits.append(split)\n","\n","# split_dataset_dict = DatasetDict({f'split_{i}': splits[i] for i in range(num_splits)})"]},{"cell_type":"markdown","metadata":{},"source":["# Reload model"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-05-30T07:35:36.120558Z","iopub.status.busy":"2024-05-30T07:35:36.120292Z","iopub.status.idle":"2024-05-30T07:35:37.613617Z","shell.execute_reply":"2024-05-30T07:35:37.612503Z","shell.execute_reply.started":"2024-05-30T07:35:36.120535Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]}],"source":["model = WhisperForConditionalGeneration.from_pretrained(\"/kaggle/input/whisper-utube-5ep/model_final\").to('cuda') # vinai/PhoWhisper-base\n","processor = WhisperProcessor.from_pretrained(\"openai/whisper-base\", language=\"vi\", task=\"transcribe\") # vinai/PhoWhisper-base\n","processor.tokenizer.pad_token = processor.tokenizer.eos_token\n","processor.tokenizer.max_length = 448\n","processor.tokenizer.set_prefix_tokens(language=\"vi\", task=\"transcribe\")\n","\n","\n","model.config.forced_decoder_ids = processor.tokenizer.get_decoder_prompt_ids(\n","    language=\"vi\", task=\"transcribe\"\n",")\n","model.config.suppress_tokens = []\n","model.generation_config.forced_decoder_ids = processor.tokenizer.get_decoder_prompt_ids(\n","    language=\"vi\", task=\"transcribe\"\n",")\n","model.generation_config.suppress_tokens = []"]},{"cell_type":"markdown","metadata":{},"source":["# Evaluate setting"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-05-30T07:35:37.615278Z","iopub.status.busy":"2024-05-30T07:35:37.614934Z","iopub.status.idle":"2024-05-30T07:35:37.645804Z","shell.execute_reply":"2024-05-30T07:35:37.645062Z","shell.execute_reply.started":"2024-05-30T07:35:37.615250Z"},"trusted":true},"outputs":[],"source":["batch_size = 1\n","eval_accumulation_steps=100\n","\n","# total_steps = (total_samples / batch_size) * num_epochs\n","training_args = TrainingArguments(\n","        output_dir='/kaggle/working/',\n","        logging_dir='/kaggle/working/',\n","        per_device_eval_batch_size=batch_size,\n","        eval_accumulation_steps=eval_accumulation_steps,\n","        metric_for_best_model='wer',\n","        greater_is_better=False,\n","        fp16=True,\n","        dataloader_num_workers=2,\n","        ignore_data_skip=True,\n","        label_names=[\"labels\"],\n","    ) \n","\n","data_collator = DataCollatorWhisperCTCEncoder(\n","    processor=processor, \n",")"]},{"cell_type":"code","execution_count":8,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-05-30T07:35:37.647176Z","iopub.status.busy":"2024-05-30T07:35:37.646893Z","iopub.status.idle":"2024-05-30T07:35:37.654775Z","shell.execute_reply":"2024-05-30T07:35:37.653671Z","shell.execute_reply.started":"2024-05-30T07:35:37.647152Z"},"trusted":true},"outputs":[],"source":["def compute_wer(eval_prediction):\n","    pred_ids = eval_prediction.predictions[0] # shape (total eval sample, max_length, vocab size)\n","    label_ids = eval_prediction.label_ids  # shape (total eval sample, max_length)\n","\n","    pred_ids = np.argmax(pred_ids, axis=-1) # -> to (total eval sample, max_length)\n","\n","    label_ids[label_ids == -100] = processor.tokenizer.pad_token_id\n","\n","    pred_str = processor.tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n","    pred_text = [s.replace('!', '') for s in pred_str]\n","    label_text = processor.tokenizer.batch_decode(label_ids, skip_special_tokens=True)\n","\n","    wer = 100 * wer_metric.compute(predictions=pred_text, references=label_text)\n","    cer = 100 * cer_metric.compute(predictions=pred_text, references=label_text)\n","    bleu = 100 * bleu_metric.compute(predictions=pred_text, references=label_text)['bleu']\n","    return { 'wer': wer,\n","             'cer': cer,\n","             'bleu': bleu}"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import numpy as np\n","\n","# Tinh so loi tu\n","def calculate_wer(ref_words, hyp_words):\n","    d = np.zeros((len(ref_words) + 1, len(hyp_words) + 1), dtype=np.uint8)\n","    for i in range(1, len(ref_words) + 1):\n","        d[i][0] = i\n","    for j in range(1, len(hyp_words) + 1):\n","        d[0][j] = j\n","    \n","    for i in range(1, len(ref_words) + 1):\n","        for j in range(1, len(hyp_words) + 1):\n","            if ref_words[i-1] == hyp_words[j-1]:\n","                cost = 0\n","            else:\n","                cost = 1\n","            d[i][j] = min(d[i-1][j] + 1,      # deletion\n","                          d[i][j-1] + 1,      # insertion\n","                          d[i-1][j-1] + cost) # substitution\n","    \n","    i = len(ref_words)\n","    j = len(hyp_words)\n","    substitutions = 0\n","    deletions = 0\n","    insertions = 0\n","    \n","    while i > 0 and j > 0:\n","        if ref_words[i-1] == hyp_words[j-1]:\n","            i -= 1\n","            j -= 1\n","        elif d[i][j] == d[i-1][j-1] + 1:\n","            substitutions += 1\n","            i -= 1\n","            j -= 1\n","        elif d[i][j] == d[i-1][j] + 1:\n","            deletions += 1\n","            i -= 1\n","        elif d[i][j] == d[i][j-1] + 1:\n","            insertions += 1\n","            j -= 1\n","    \n","    deletions += i\n","    insertions += j\n","    \n","    return substitutions, deletions, insertions\n","\n","def calculate_wer_for_lists(reference_list, hypothesis_list):\n","    total_substitutions = 0\n","    total_deletions = 0\n","    total_insertions = 0\n","    \n","    for reference, hypothesis in zip(reference_list, hypothesis_list):\n","        ref_words = reference.split()\n","        hyp_words = hypothesis.split()\n","        substitutions, deletions, insertions = calculate_wer(ref_words, hyp_words)\n","        \n","        total_substitutions += substitutions\n","        total_deletions += deletions\n","        total_insertions += insertions\n","    \n","    return total_substitutions, total_deletions, total_insertions\n","\n","# dem so tu\n","def count_words(strings):\n","    total_words = 0\n","    for string in strings:\n","        words = string.split()\n","        total_words += len(words)\n","    return total_words"]},{"cell_type":"markdown","metadata":{},"source":["# Evaluate"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-05-30T07:35:37.656162Z","iopub.status.busy":"2024-05-30T07:35:37.655898Z","iopub.status.idle":"2024-05-30T07:37:03.151720Z","shell.execute_reply":"2024-05-30T07:37:03.150638Z","shell.execute_reply.started":"2024-05-30T07:35:37.656139Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n","dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n","  warnings.warn(\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"}],"source":["trainer = Trainer(\n","        model=model,\n","        data_collator=data_collator,\n","        args=training_args,\n","        compute_metrics=compute_wer,\n","    )\n","\n","\n","trainer.evaluate(eval_dataset=all_dataset_test_vectorized)\n","# pred = trainer.predict(all_dataset_test_vectorized)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-30T07:37:03.171444Z","iopub.status.busy":"2024-05-30T07:37:03.170628Z","iopub.status.idle":"2024-05-30T07:37:46.933199Z","shell.execute_reply":"2024-05-30T07:37:46.932251Z","shell.execute_reply.started":"2024-05-30T07:37:03.171406Z"},"trusted":true},"outputs":[],"source":["# for trainer.predict\n","pred_ids = pred.predictions[0]\n","label_ids = pred.label_ids\n","\n","pred_ids = np.argmax(pred_ids, axis=-1)\n","label_ids[label_ids == -100] = processor.tokenizer.pad_token_id\n","\n","pred_str = processor.tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n","pred_text = [s.replace('!', '') for s in pred_str]\n","label_text = processor.tokenizer.batch_decode(label_ids, skip_special_tokens=True)\n","\n","total_substitutions, total_deletions, total_insertions = calculate_wer_for_lists(label_text, pred_text)\n","\n","print(f\"Tổng số lỗi thay thế (S): {total_substitutions}\")\n","print(f\"Tổng số lỗi xóa (D): {total_deletions}\")\n","print(f\"Tổng số lỗi chèn thêm (I): {total_insertions}\")\n","print(f\"Tổng số từ (N): {count_words(label_text)}\")"]},{"cell_type":"markdown","metadata":{},"source":["# DEMO"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["processor = WhisperProcessor.from_pretrained(\"vinai/PhoWhisper-base\", language=\"vi\", task=\"transcribe\") # vinai/PhoWhisper-base\n","processor.tokenizer.pad_token = processor.tokenizer.eos_token # openai/whisper-base\n","processor.tokenizer.max_length = 448\n","\n","processor.tokenizer.set_prefix_tokens(language=\"vi\", task=\"transcribe\")\n","\n","forced_decoder_ids = processor.get_decoder_prompt_ids(language=\"vi\", task=\"transcribe\")"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import librosa\n","input_speech, rate = librosa.load('/kaggle/input/youtube-test2/youtube_5.wav', sr=16000)\n","\n","input_features = processor(input_speech, sampling_rate=rate, return_tensors=\"pt\").input_features"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["model_trained = WhisperForConditionalGeneration.from_pretrained('vinai/PhoWhisper-base')\n","predicted_ids_model_trained = model_trained.generate(input_features, forced_decoder_ids=forced_decoder_ids)\n","pho = processor.batch_decode(predicted_ids_model_trained, skip_special_tokens=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["print(\"True: chị vào viện tất cả với chị đều xúc động\")\n","print('pho_fine:', pho_fine)\n","print('pho:', pho)\n","print('whisper_fine:', whisper_fine)\n","print('whisper:', whisper)"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":4954566,"sourceId":8341680,"sourceType":"datasetVersion"},{"datasetId":4955695,"sourceId":8343245,"sourceType":"datasetVersion"},{"datasetId":5034287,"sourceId":8467729,"sourceType":"datasetVersion"},{"datasetId":5048818,"sourceId":8467930,"sourceType":"datasetVersion"},{"datasetId":5049276,"sourceId":8468537,"sourceType":"datasetVersion"},{"datasetId":5103158,"sourceId":8541923,"sourceType":"datasetVersion"},{"datasetId":5103176,"sourceId":8541945,"sourceType":"datasetVersion"},{"sourceId":178682618,"sourceType":"kernelVersion"}],"dockerImageVersionId":30698,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
