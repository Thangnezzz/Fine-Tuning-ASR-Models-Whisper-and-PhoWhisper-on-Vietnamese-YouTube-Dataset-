#  Fine-Tuning ASR Models: Whisper and PhoWhisper on Vietnamese YouTube Dataset 
Automatic Speech Recognition (ASR), or automatic speech recognition, is a technology that converts human speech into text using machine learning and signal processing techniques. ASR systems work through the following steps: audio acquisition, signal processing to remove noise, audio feature extraction (such as MFCCs), and using machine learning models such as HMMs, RNNs or DNNs to recognize and decode signals into text. ASR applications are diverse, including virtual assistants (Siri, Google Assistant), voice control systems, speech-to-text conversion, automatic translation, and educational support. However, ASR faces many challenges such as noisy environments, diverse voices, fast speaking speed and context, as well as updating new vocabulary and languages. Despite many challenges, ASR promises to bring great benefits in many areas of life and technology.

Automatic Speech Recognition (ASR) systems have made great strides in recent years. However, to build an accurate ASR system, extensive training on large datasets is required, especially for resource-constrained languages ​​such as Vietnamese. In this study, we introduce two fine-tuned models, Whisper and PhoWhisper, applied to the Vietnamese dataset. Both models achieve good results, marking an important step forward in achieving accurate and high-quality language conversion.

# Dataset
The dataset we used is called “viet_youtube_asr_corpus_v2” and is collected from the social networking platform YouTube. This dataset includes more than 100 hours of audio content, reflecting the diversity and richness of the Vietnamese language across many different genres such as entertainment, education, news, and many other fields. The dataset has been made public on HuggingFace, a reputable platform for artificial intelligence researchers and developers, making it easy to access and use for research and learning purposes.
